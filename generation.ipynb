{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torchaudio\n",
    "import torch\n",
    "from audiocraft.utils.notebook import display_audio, write_audio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "c:\\Users\\Jacob\\anaconda3\\envs\\audiocraft\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Jacob\\anaconda3\\envs\\audiocraft\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment Params\n",
    "# Optionally generate from custom weights\n",
    "# Pretrained example\n",
    "# weights_path = None\n",
    "# experiment_name = f\"pretrained\"\n",
    "# Finetuned\n",
    "trial = 29\n",
    "experiment_name = f\"lm_epoch_{trial}\"\n",
    "weights_path = f\"weights/{experiment_name}.pt\"\n",
    "\n",
    "if weights_path:\n",
    "    model.lm.load_state_dict(torch.load(weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=250,\n",
    "    duration=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Validation Examples\n",
    "directory = \"../dataset/val/\"\n",
    "# Generate Test Examples\n",
    "# directory = \"../dataset/test/\"\n",
    "audio_files = []\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        audio_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to output-lm_epoch_29\\J.J. Johnson - Blue Mode.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - Blues In The Closet.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - Crazy Rhythm.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - Elora.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - My Funny Valentine.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - Tea Pot.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - Walkin'.mp3\n",
      "Writing to output-lm_epoch_29\\J.J. Johnson - Yesterdays.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - In n Out (2).mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - In n Out.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - Johnny Come Lately.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - Punjab.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - Serenity.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - The Sidewinder.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - Totem Pole.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Henderson - U.M.M.G. (Upper Manhattan Medical Group).mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - Body and Soul (2).mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - Body And Soul.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - Central Park West.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - I Can't Get Started.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - Little Willie Leaps In.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - Lonnie's Lament.mp3\n",
      "Writing to output-lm_epoch_29\\Joe Lovano - Work.mp3\n",
      "Writing to output-lm_epoch_29\\John Abercrombie - Ralph's Piano Waltz.mp3\n"
     ]
    }
   ],
   "source": [
    "output_dir = f\"output-{experiment_name}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for file in audio_files:\n",
    "    prompt_waveform, prompt_sr = torchaudio.load(file)\n",
    "    prompt_duration = 5\n",
    "    prompt_waveform = prompt_waveform[..., :int(prompt_duration * prompt_sr)]\n",
    "    output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, progress=True, return_tokens=True)\n",
    "    # display_audio(output[0], sample_rate=32000)\n",
    "    output_filename = os.path.join(output_dir, file.split(\"/\")[-1])\n",
    "    write_audio(output[0], sample_rate=32000, filename=output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to output-test-pretrained\\John Coltrane - 26-2.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Bessie's Blues.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Blue Train.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Blues By Five.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Body and Soul (Alternate Take).mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Body and Soul.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Countdown.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Giant Steps (2).mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Giant Steps.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Impressions (1961).mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Impressions (1963).mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Mr. P.C..mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - My Favorite Things (2).mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - My Favorite Things.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Nature Boy.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Nutty.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Oleo.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - So What.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Soultrane.mp3\n",
      "Writing to output-test-pretrained\\John Coltrane - Trane's Blues.mp3\n",
      "Writing to output-test-pretrained\\Zoot Sims - Night And Day (1950).mp3\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "# Pretrained example\n",
    "weights_path = None\n",
    "experiment_name = f\"pretrained\"\n",
    "# Finetuned\n",
    "# trial = 24\n",
    "# experiment_name = f\"lm_epoch_{trial}\"\n",
    "# weights_path = f\"weights/{experiment_name}.pt\"\n",
    "\n",
    "if weights_path:\n",
    "    model.lm.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=250,\n",
    "    duration=30\n",
    ")\n",
    "\n",
    "# Generate Test Examples\n",
    "directory = \"../dataset/test/\"\n",
    "# Generate Test Examples\n",
    "# directory = \"../dataset/test/\"\n",
    "audio_files = []\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        audio_files.append(f)\n",
    "\n",
    "output_dir = f\"output-test-{experiment_name}\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for file in audio_files:\n",
    "    prompt_waveform, prompt_sr = torchaudio.load(file)\n",
    "    prompt_duration = 5\n",
    "    prompt_waveform = prompt_waveform[..., :int(prompt_duration * prompt_sr)]\n",
    "    output = model.generate_continuation(prompt_waveform, prompt_sample_rate=prompt_sr, progress=True, return_tokens=True)\n",
    "    # display_audio(output[0], sample_rate=32000)\n",
    "    output_filename = os.path.join(output_dir, file.split(\"/\")[-1])\n",
    "    write_audio(output[0], sample_rate=32000, filename=output_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
